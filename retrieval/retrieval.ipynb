{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval\n",
        "\n",
        "This notebook shows an example of how to train a deep model for recommendation retrieval in TensorFlow. More specifically, this notebook shows how to train both an exact and approximated retrieval model for user-to-item and item-to-item retrieval.\n",
        "\n",
        "The dataset used is MovieLens 100K dataset, however any costum dataset can be used.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zAJxLTwHkMgw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The retrieval task consists of two steps:\n",
        "\n",
        "  1- Build a two-towers model. A two-tower model for retrieval is a neural network architecture that consists of two sub-models: a query model and a candidate model. The query model computes a vector representation (or embedding) for a user or a query using features such as user history, preferences, or context. The candidate model computes a vector representation for an item or a candidate using features such as item attributes, ratings, or popularity. \n",
        "\n",
        "  2- The similarity between the query and candidate embeddings is then used to score and rank the candidates for retrieval."
      ],
      "metadata": {
        "id": "rSH2zgIdp9r0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vJOdh9WbTpd"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets\n",
        "!pip install -q tensorflow-ranking\n",
        "!pip install -q scann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZGYDaF-m5wZ"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_recommenders as tfrs\n",
        "\n",
        "from utils.feature_extraction import FeatureExtractionTower\n",
        "from utils.models import RetrievalModel\n",
        "from utils.preprocessing import *\n",
        "\n",
        "import logging\n",
        "tf.get_logger().setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PAqjR4a1RR4"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaQhqcLGP0jL"
      },
      "outputs": [],
      "source": [
        "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
        "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
        "\n",
        "ratings = ratings.map(lambda x: {\n",
        "    \"movie_title\": x[\"movie_title\"],\n",
        "    \"user_id\": x[\"user_id\"],\n",
        "    \"movie_id\": x[\"movie_id\"],\n",
        "    \"user_occupation_text\": x[\"user_occupation_text\"]\n",
        "})\n",
        "movies = movies.map(lambda x: {\"movie_title\": x[\"movie_title\"], \"movie_id\": x[\"movie_id\"]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1-KQV2ynMdh"
      },
      "outputs": [],
      "source": [
        "for x in ratings.take(1):\n",
        "    pprint.pprint(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu4XSa_G1nyN"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rS0eDfkjnjJL"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(80_000)\n",
        "test = shuffled.skip(80_000).take(20_000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCi-seR86qqa"
      },
      "source": [
        "## Model definition\n",
        "\n",
        "We build a user tower and item tower and feed them to a retrival task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z20PyfSXP3Um"
      },
      "source": [
        "### The query/user tower\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_tower = FeatureExtractionTower(ratings, cats_to_hash_embedding=[\"user_id\"],text_to_embedding=[\"user_occupation_text\"])"
      ],
      "metadata": {
        "id": "OTlvt4A2PQaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG4YFy9SQ08d"
      },
      "source": [
        "### The candidate/movie tower\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_tower = FeatureExtractionTower(ratings, text_to_embedding=[\"movie_title\", \"movie_title\"])\n"
      ],
      "metadata": {
        "id": "4SyKJgvlSV4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r10RiPtqVIAl"
      },
      "source": [
        "### Metrics\n",
        "\n",
        "We want to know how well our model can predict the userâ€™s preference for a movie. We have some data that tells us which movies the user liked. We can use these as positive examples and compare them with all the other movies that the user did not rate. If the model gives a higher score to the positive examples than to the negative ones, it means it is very accurate.\n",
        "\n",
        "To measure this, we can use the tfrs.metrics.FactorizedTopK metric. It needs one input: a dataset of all the movies that we use as negative examples for testing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dLDL6pZVPO8"
      },
      "outputs": [],
      "source": [
        "metrics = tfrs.metrics.FactorizedTopK(\n",
        "  candidates=movies.batch(128).map(movie_tower.call)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDN_LJGlnRGo"
      },
      "source": [
        "## Fitting and evaluating\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aW63YaqP2wCf"
      },
      "outputs": [],
      "source": [
        "model = RetrievalModel(user_tower, movie_tower, metrics)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53QJwY1gUnfv"
      },
      "outputs": [],
      "source": [
        "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
        "cached_test = test.batch(4096).cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxPntlT8EFOZ"
      },
      "outputs": [],
      "source": [
        "model.fit(cached_train, epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-zu6HLODNeI"
      },
      "outputs": [],
      "source": [
        "model.evaluate(cached_test, return_dict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB2v43NJU3Xf"
      },
      "source": [
        "## Making predictions\n",
        "\n",
        "Now that we have a model, we would like to be able to make predictions. We can use the `tfrs.layers.factorized_top_k.BruteForce` layer to do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRD6bEtZW_8j"
      },
      "outputs": [],
      "source": [
        "# Create a model that takes in raw query features, and\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(model.user_tower)\n",
        "# recommends movies out of the entire movies dataset.\n",
        "index.index_from_dataset(\n",
        "  tf.data.Dataset.zip((movies.map(lambda x: x[\"movie_title\"]).batch(100), movies.batch(100).map(model.movie_tower)))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, titles = index({\"user_id\": np.array([\"42\"]), \"user_occupation_text\":tf.constant([\"doctor\"]), \"movie_title\": [\"Speed (1994)\"]})\n",
        "print(f\"Recommendations for user 42: {titles[0, :3]}\")"
      ],
      "metadata": {
        "id": "mq-9K6wwpGg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOoLv6ZMKg0L"
      },
      "source": [
        "Of course, the `BruteForce` layer is going to be too slow to serve a model with many possible candidates. We can also export an approximate retrieval index to speed up predictions. This will make it possible to efficiently surface recommendations from sets of tens of millions of candidates.\n",
        "\n",
        "To do so, we can use the `scann` package; we can use the TFRS `ScaNN` layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTz8yxyp5uwU"
      },
      "outputs": [],
      "source": [
        "scann_index = tfrs.layers.factorized_top_k.ScaNN(model.user_tower)\n",
        "scann_index.index_from_dataset(\n",
        "  tf.data.Dataset.zip((movies.map(lambda x: x[\"movie_title\"]).batch(100), movies.batch(100).map(model.movie_tower)))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpLnoUv256bS"
      },
      "source": [
        "This layer will perform _approximate_ lookups: this makes retrieval slightly less accurate, but orders of magnitude faster on large candidate sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Te_MGu1Q6JrU"
      },
      "outputs": [],
      "source": [
        "# Get recommendations.\n",
        "_, titles = scann_index({\"user_id\": np.array([\"148\"]), \"user_occupation_text\":tf.constant([\"doctor\"])})\n",
        "print(f\"Recommendations for user 42: {titles[0, :3]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YKpU9X7ERnN"
      },
      "source": [
        "## Item-to-item recommendation\n",
        "\n",
        "We can use the learned models to perform item-to-item or user-to-user recommendations.\n",
        "\n",
        "Another approache would build a two item/users towers (for the query and candidate item), and train the model using (query item, candidate item) pairs. These could be constructed from movies that was seen by same user."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scann_index = tfrs.layers.factorized_top_k.ScaNN(model.movie_tower)\n",
        "scann_index.index_from_dataset(\n",
        "  tf.data.Dataset.zip((movies.map(lambda x: x[\"movie_title\"]).batch(100), movies.batch(100).map(model.movie_tower)))\n",
        ")"
      ],
      "metadata": {
        "id": "RlShyPVziVRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get recommendations.\n",
        "_, titles = scann_index({\"movie_title\":tf.constant([\"Beautiful Thing (1996)\"])})\n",
        "print(f\"Recommendations for movie Beautiful Thing (1996): {titles[0, :3]}\")"
      ],
      "metadata": {
        "id": "zEn6FYpSjJVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0UFyyocksOF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "basic_retrieval.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}