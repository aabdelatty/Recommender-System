{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6r3nWZS_m7q"
   },
   "source": [
    "# Pointwise ranking\n",
    "\n",
    "This notebook shows an example of how to train a deep pointwise ranker in TensorFlow.\n",
    "\n",
    "The dataset used is MovieLens 100K dataset, however any costum dataset can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gr_BrcNMKji6"
   },
   "outputs": [],
   "source": [
    "# !pip install -q tensorflow-recommenders\n",
    "# !pip install -q --upgrade tensorflow-datasets\n",
    "# !pip install -q tensorflow-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ekaJkcuHsiY"
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import tensorflow_ranking as tfr\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "from utils.feature_extraction import FeatureExtractionTower\n",
    "from utils.models import RankingModel\n",
    "from utils.preprocessing import *\n",
    "\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNEB3VRs3bOS"
   },
   "source": [
    "## Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-VF30hJn5-3"
   },
   "outputs": [],
   "source": [
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
    "\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": x[\"user_rating\"],\n",
    "    \"user_occupation_text\": x[\"user_occupation_text\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIBH-Axc7oqB"
   },
   "source": [
    "## Data preprocessing\n",
    "\n",
    "We transform the dataset so that each example contains a user info and a list of items rated by that user. Some items in the list will be ranked higher than others; the goal of our model will be to make predictions that match this ordering.\n",
    "\n",
    "This transformation can be applied to any custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tvm6n1zRAoqi"
   },
   "outputs": [],
   "source": [
    "user_features = [\"user_id\", \"user_occupation_text\"]\n",
    "item_features = [\"movie_title\"]\n",
    "label_name = \"user_rating\"\n",
    "num_list_per_user=50\n",
    "num_examples_per_list=5\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X99torl5z4Iu"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# Split between train and tests sets, as before.\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "# We sample 50 lists for each user for the training data. For each list we\n",
    "# sample 5 movies from the movies the user rated.\n",
    "train = sample_listwise(\n",
    "                train,\n",
    "                user_features = user_features,\n",
    "                item_features = item_features,\n",
    "                label_name = label_name,\n",
    "                num_list_per_user=num_list_per_user,\n",
    "                num_examples_per_list=num_examples_per_list,\n",
    "                seed=seed\n",
    "            )\n",
    "test = sample_listwise(\n",
    "                test,\n",
    "                user_features = user_features,\n",
    "                item_features = item_features,\n",
    "                label_name = label_name,\n",
    "                num_list_per_user=num_list_per_user,\n",
    "                num_examples_per_list=num_examples_per_list,\n",
    "                seed=seed\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zuAfGrgCBJP"
   },
   "source": [
    "We can inspect an example from the training data. The example includes a user id, a list of 10 movie ids, and their ratings by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AO52eZqOzOUV"
   },
   "outputs": [],
   "source": [
    "for example in train.take(1):\n",
    "    pprint.pprint(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aM3uu5hgN4-v"
   },
   "source": [
    "## Model definition\n",
    "\n",
    "We build a user tower and item tower and feed them to a ranking task.\n",
    "We use  \n",
    "\n",
    "We train the model to minimize the mean squared error between the actual ratings and predicted ratings. Therefore, this loss is computed individually for each movie and the training is pointwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bj1Rm2bM6Jgf"
   },
   "outputs": [],
   "source": [
    "user_tower = FeatureExtractionTower(ratings, cats_to_embedding=[\"user_id\", \"user_occupation_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QbYwSF652D1A"
   },
   "outputs": [],
   "source": [
    "movie_tower = FeatureExtractionTower(ratings, cats_to_embedding=[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eT4iC0_A3Umg"
   },
   "outputs": [],
   "source": [
    "movie_tower.call({\"user_id\": np.array([\"42\"]), \"movie_title\": tf.constant([\"Speed (1994)\", \"Speed (1994)\"])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcTElTWbOImt"
   },
   "source": [
    "## Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7U530Yk-s-g9"
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F0lq0Nq7_xTW"
   },
   "outputs": [],
   "source": [
    "mse_model = RankingModel(user_tower, movie_tower, tf.keras.losses.MeanSquaredError(), num_examples_per_list)\n",
    "mse_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6NBl543nRtIo"
   },
   "outputs": [],
   "source": [
    "mse_model.fit(cached_train, epochs=epochs, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hfPgRvnXSJwm"
   },
   "outputs": [],
   "source": [
    "mse_model_result = mse_model.evaluate(cached_test, return_dict=True)\n",
    "print(\"NDCG of the MSE Model: {:.4f}\".format(mse_model_result[\"ndcg_metric\"]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "listwise_ranking.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
